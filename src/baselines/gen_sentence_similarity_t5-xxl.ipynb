{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b90d278f-74e8-44e5-b7a9-2540e287ae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0360f19e-28fe-4cf9-a8dd-26668635ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config file to get the ontology categories\n",
    "config_path = 'config/dbpedia_webnlg_prompt_gen_config.json'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "ontology_list = config['onto_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aeba4c6-874d-4ac3-9985-17462f86f55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:127: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /opt/pytorch/pytorch/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SentenceTransformer model\n",
    "# Note: T5-XXL is a very large model (11B parameters) and may not run on standard hardware.\n",
    "# Make sure you have the necessary resources before loading this model.\n",
    "model_name = 'sentence-t5-xxl'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a93c6b-d062-40c9-8fb1-e2fafcdb7dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "test_data_path = '../../data/dbpedia_webnlg/test/'\n",
    "train_data_path = '../../data/dbpedia_webnlg/train/'\n",
    "output_path = '../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fec48edd-ca17-4abe-b7a3-2646fcaddb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ontology: 10_city\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 7/7 [01:41<00:00, 14.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5/5 [01:23<00:00, 16.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [00:00<00:00, 4421.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/10_city_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 11_meanoftransportation\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:55<00:00, 18.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 7/7 [02:21<00:00, 20.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [00:00<00:00, 3714.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/11_meanoftransportation_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 12_company\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:27<00:00, 13.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 4/4 [00:56<00:00, 14.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:00<00:00, 4708.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/12_company_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 13_celestialbody\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [01:03<00:00, 21.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 4/4 [01:40<00:00, 25.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:00<00:00, 3996.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/13_celestialbody_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 14_musicalwork\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 7/7 [02:13<00:00, 19.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:56<00:00, 18.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:00<00:00, 4663.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/14_musicalwork_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 15_athlete\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 4/4 [01:11<00:00, 17.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 6/6 [02:11<00:00, 21.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:00<00:00, 4055.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/15_athlete_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 16_university\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [01:34<00:00, 31.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:57<00:00, 19.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:00<00:00, 4664.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/16_university_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 17_sportsteam\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 4/4 [01:45<00:00, 26.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 4/4 [01:27<00:00, 21.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:00<00:00, 4553.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/17_sportsteam_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 18_politician\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5/5 [01:21<00:00, 16.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 6/6 [01:53<00:00, 18.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:00<00:00, 4347.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/18_politician_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 19_food\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5/5 [01:51<00:00, 22.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 8/8 [02:15<00:00, 16.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:00<00:00, 3833.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/19_food_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 1_writtenwork\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 4/4 [01:21<00:00, 20.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 7/7 [02:07<00:00, 18.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:00<00:00, 4709.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/1_writtenwork_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 2_airport\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:45<00:00, 15.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 8/8 [02:46<00:00, 20.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 4621.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/2_airport_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 3_artist\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:44<00:00, 14.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 10/10 [02:49<00:00, 16.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [00:00<00:00, 4568.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/3_artist_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 4_film\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 4/4 [01:21<00:00, 20.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5/5 [01:26<00:00, 17.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:00<00:00, 4999.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/4_film_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 5_monument\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:14<00:00, 14.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [01:00<00:00, 20.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 3875.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/5_monument_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 6_comicscharacter\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:19<00:00,  9.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:43<00:00, 14.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 4174.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/6_comicscharacter_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 7_scientist\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5/5 [01:33<00:00, 18.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 4/4 [01:09<00:00, 17.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149/149 [00:00<00:00, 4833.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/7_scientist_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 8_astronaut\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:46<00:00, 15.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:43<00:00, 14.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:00<00:00, 4276.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/8_astronaut_test_train_similarity.json\n",
      "\n",
      "Processing ontology: 9_building\n",
      "Computing embeddings for test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 4/4 [00:57<00:00, 14.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 6/6 [01:43<00:00, 17.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities and finding top similar sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:00<00:00, 4642.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../../data/dbpedia_webnlg/baselines/test_train_sent_similarity/9_building_test_train_similarity.json\n",
      "\n",
      "Processing completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of top similar sentences to retrieve\n",
    "top_k = 5\n",
    "\n",
    "# Process each ontology category\n",
    "for ontology in ontology_list:\n",
    "    print(f'Processing ontology: {ontology}')\n",
    "    \n",
    "    # Extract the number from the ontology string\n",
    "    ontology_num = re.search(r'(\\d+)_', ontology).group(1)\n",
    "    category = ontology.split('_', 1)[1]  # Get category name after number\n",
    "    \n",
    "    # Load test data\n",
    "    test_file = os.path.join(test_data_path, f'ont_{ontology_num}_{category}_test.jsonl')\n",
    "    test_sentences = []\n",
    "    test_ids = []\n",
    "    with open(test_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line.strip())\n",
    "            test_sentences.append(data['sent'])\n",
    "            test_ids.append(data['id'])\n",
    "\n",
    "    # Load train data\n",
    "    train_file = os.path.join(train_data_path, f'ont_{ontology_num}_{category}_train.jsonl')\n",
    "    train_sentences = []\n",
    "    train_ids = []\n",
    "    with open(train_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line.strip())\n",
    "            train_sentences.append(data['sent'])\n",
    "            train_ids.append(data['id'])\n",
    "\n",
    "    # Compute embeddings for test and train sentences\n",
    "    print('Computing embeddings for test sentences...')\n",
    "    test_embeddings = model.encode(test_sentences, convert_to_tensor=True, show_progress_bar=True)\n",
    "    print('Computing embeddings for train sentences...')\n",
    "    train_embeddings = model.encode(train_sentences, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "    # Compute similarities and find top-k similar sentences for each test sentence\n",
    "    similarity_results = {}\n",
    "    print('Computing similarities and finding top similar sentences...')\n",
    "    for idx, test_embedding in enumerate(tqdm(test_embeddings)):\n",
    "        cosine_scores = util.cos_sim(test_embedding, train_embeddings)[0]\n",
    "        top_results = torch.topk(cosine_scores, k=top_k)\n",
    "        similar_train_ids = [train_ids[i] for i in top_results[1]]\n",
    "        similarity_results[test_ids[idx]] = similar_train_ids\n",
    "\n",
    "    # Save the results to the output file\n",
    "    output_file = os.path.join(output_path, f'{ontology}_test_train_similarity.json')\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(similarity_results, f, indent=4)\n",
    "\n",
    "    print(f'Results saved to {output_file}\\n')\n",
    "\n",
    "print('Processing completed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
